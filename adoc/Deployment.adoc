ifeval::["{lang}" == "en"]
== Deployment
This deployment section should be seen as a supplement online https://www.suse.com/documentation/[documentation]. Specifically, the https://www.suse.com/documentation/suse-enterprise-storage-5/book_storage_deployment/data/book_storage_deployment.html[SUSE Enterprise Storage 5 Deployment Guide] as well as https://www.suse.com/documentation/sles-12/book_sle_admin/data/book_sle_admin.html[SUSE Linux Enterprise Server Administration Guide]. It is assumed that a Subscription Management Tool server exists within the environment. If not, please follow the information in https://www.suse.com/documentation/sles-12/book_smt/data/book_smt.html[Subscription Management Tool (SMT) for SLES] to make one available. The emphasis is on specific design and configuration choices.

In this document we use `example.com` as the domain name for the nodes, replace it with your real domain name in your own installation.

=== Network Considerations
The following considerations for the network configuration should be attended to:

* Ensure that all network switches are updated with consistent firmware versions.
* Network IP addressing and IP ranges need proper planning. In optimal environments, a dedicated storage subnet should be used for all SUSE Enterprise Storage nodes on the primary network, with a separate, dedicated subnet for the cluster network. Depending on the size of the installation, ranges larger than /24 may be required. When planning the network, current as well as future growth should be taken into consideration.

=== Hardware Considerations
The following considerations for the hardware platforms should be attended to:

* Configure the system to performance mode if you prefer performance over power efficiency. To change that, reboot the system, press kbd:[Del] when prompted during system initializing to boot into the BIOS setup menu. Then select menu:Advanced[Performance Config > Power Policy], select btn:[Performance] for best performance or btn:[Efficiency] for power efficiency.
+
NOTE: The {vendor} {vPlatform} server platform currently does not support OS controlled processor frequency scaling. The only way to change the system power policy is to reboot and change it in the system BIOS.

* In case you can't see the SUSE Installer screen after booting up the SUSE installation medium, check the BIOS option menu:Advanced[MISC Config > Support SPCR] and set it to btn:[Disabled].

* A RAID-1 volume consists of two 600GB SAS hard drive is enough for the OS disk.

* If hard drives are connected to hardware RAID controller(s) with hardware write cache, configure each of them as individual RAID-0 volume and make sure hardware caching is enabled.

* Try to balance the drives across controllers, ports, and enclosures. Avoid making one part of the I/O subsystem busy while leaving other parts idle.

* If SAS/SATA SSDs are installed, make sure to attach then to a dedicated HBA or RAID controller rather than to the controller that already has many HDDs attached.

=== Operating System Considerations
The following considerations for the Operating System should be attended to:

* The underlying OS for SES {SESVersion} is SUSE Linux Enterprise Server {SLESVersion}. Other OS versions are not supported. During installation, make sure below addon modules are selected.

** Base system module
** Server Applications module
** SUSE Enterprise Storage 6

* During installation, don't select any GUI components such as X-Window system, GNOME or KDE, as they are not needed to run the storage service. 

* It is highly recommended to register the systems to an update server to install the latest updates available, helping to ensure the best experience possible. The systems could be registered directly to SUSE Customer Center if it is a small cluster, or could be registered to a local SMT or RMT server when the cluster is large. Installing updates from a local SMT/RMT server will dramatically reduce the time required for updates to be downloaded to all nodes.
+
TIP: Refer to https://documentation.suse.com/en-us/sles/15-SP1/single-html/SLES-rmt/[Repository Mirroring Tool Guide] for how to setup a RMT server.

* Ensure that the operating system is installed on the correct device. Especially on OSD nodes, the installer may not choose the right one from many available drives.

* Hostnames of all nodes should be properly configured. Full hostname (i.e. with domain name) should always be assigned for each node or else the deployment may fail. Make sure `hostname -s`, `hostname -f` and `hostname -i` commands return proper results for short hostname (without dots), full hostname and IP addresses. Each node must also be able to resolve hostname of all nodes, including its own name.
** For a rather small cluster, hosts files can be used for name resolution. Also see <<_copy_files_to_all_cluster_nodes>> for how to conveniently keep the hosts on all nodes in sync.
** Having a DNS server is recommended for a larger cluster. See the https://documentation.suse.com/sles/15-SP1/single-html/SLES-admin/#cha-dns[SUSE Linux Enterprise Server Administration Guide] for how to setup a DNS server.

* Do ensure that NTP is configured to point to a valid, physical NTP server. This is critical for SUSE Enterprise Storage to function properly, and failure to do so can result in an unhealthy or non-functional cluster. And keep in mind that the NTP service is not designed to be run on an virtualized environment, so make sure the NTP server been used is an physical machine or it may cause strange clock drifting problem.

=== SUSE Enterprise Storage Installation & Configuration
==== Software Deployment Configuration (Deepsea and Salt)
Salt, along with DeepSea, is a stack of components that help deploy and manage server infrastructure. It is very scalable, fast, and relatively easy to get running.

There are three key Salt imperatives that need to be followed:

* The Salt Master is the host that controls the entire cluster deployment. Ceph itself should NOT be running on the master as all resources should be dedicated to Salt master services. In our scenario, we used the Admin host as the Salt master.
* Salt minions are nodes controlled by Salt master. OSD, monitor, and gateway nodes are all Salt minions in this installation.
* Salt minions need to correctly resolve the Salt master’s host name.

Deepsea consists of series of Salt files to automate the deployment and management of a Ceph cluster. It consolidates the administrator’s decision making in a single location around cluster layout, node role assignment and drive assignment. Deepsea collects each set of tasks into a goal or stage.

The following steps, performed in order, were used for this reference implementation. All commands were run by root user.

==== Prepare All Nodes
. Install salt master on the Admin node:
+
----
zypper in salt-master
----
+

. Start the salt-master service and enable start on boot:
+
----
systemctl enable --now salt-master.service
----
+

. Install the salt-minion on all cluster nodes (including the Admin):
+
----
zypper in salt-minion
----
+

. Configure all minions to connect to the Salt master:
+
Create a new file `/etc/salt/minion.d/master.conf` with the following content: 
+
----
master: admin.example.com
----
+

. Restart the salt-minion service and enable it:
+
----
systemctl restart salt-minion.service
systemctl enable salt-minion.service
----
+

. List Salt fingerprints on all the minions:
+
----
salt-call --local key.finger
----
+

. List all incoming minion fingerprints on the Salt master, verify them against the fingerprints on each minions to make sure they all match. If they do, accept all Salt keys on the Salt master:
+
----
salt-key -F
salt-key --accept-all
salt-key --list-all
----
+

. Verify if Salt works properly by "ping" each minions from the Salt master. They should all return True on success:
+
----
salt '*' test.ping
----

. Now check and make sure the time on all nodes are the same. In later stage Deepsea will setup all nodes to synchronize time from the admin node, but before that is done, strange errors may occur if time on each node are largely out of sync. So it's better to set all nodes to the same time manually first. For example, run below command on your admin node:
+
----
salt '*' cmd.run 'date -s "2020-03-19 17:30:00"'
----
Use your actual time in the same format when running the command. It doesn't have to be super accurate, as later all nodes will be synchronized by the chrony time service.


==== Prepare OSD Disks on OSD Nodes
If the OSD nodes were used in a prior installation, or the disks are used by other applications before, zap ALL the OSD disks first.

IMPORTANT: This must be done on all the OSD disks that were used before, or else the deployment may fail when activating OSDs.

WARNING: Below commands should not be copied and executed on your installation blindly. The device names used below are just examples, you need to change them to match only the OSD disks in your own installation. Failed to use the correct device name may erase your OS disk or other disks that may hold valuable data.

. Wipe the beginning of each partition:
+
----
for partition in /dev/sdX[0-9]*
do
  dd if=/dev/zero of=$partition bs=4096 count=1 oflag=direct
done
----
+

. Wipe the beginning of the drive:
+
----
dd if=/dev/zero of=/dev/sdX bs=512 count=34 oflag=direct
----
+
	
. Wipe the end of the drive:
+
----
dd if=/dev/zero of=/dev/sdX bs=512 count=33 \
  seek=$((`blockdev --getsz /dev/sdX` - 33)) oflag=direct
----

==== Install and Configure Deepsea on Admin Node
. Install deepsea package on Admin node:
+
----
# zypper in deepsea
----
+

. Check _/srv/pillar/ceph/master_minion.sls_ for correctness.

. Check _/srv/pillar/ceph/deepsea_minions.sls_ file, make sure the deepsea_minions option targets the correct nodes. In the usual case, it can simply be put like below to match all Salt minions in the cluster:
+
----
deepsea_minions: '*'
----
+

. Create _/srv/pillar/ceph/stack/ceph/cluster.yml_ [[create-cluster-yml,Create cluster.yml]] with below options: 
+
----
cluster_network: <net/mask of cluster network>
public_network: <net/mask of public network>
time_server: <Address of NTP server, if this line is omitted admin node will be used>
----

==== Deploy Using Deepsea
At this point Deepsea commands can be run on the admin node to deploy the cluster.

[TIP]
====
Each command can be run either as:
----
salt-run state.orch ceph.stage.<stage name>
----

Or:
----
deepsea stage run ceph.stage.<stage name>
----

The latter form is preferred as it outputs real time progress.
====

===== Stage 0: Prepare
During this stage, all required updates are applied and your system may be rebooted.
----
deepsea stage run ceph.stage.0
----

IMPORTANT: If the Salt master reboots during Stage 0, you need to run Stage 0 again after it boots up.

Optionally, create the _/var/lib/ceph_ btrfs subvolume:
----
salt-run state.orch ceph.migrate.subvolume
----

===== Stage 1: Discovery
During this stage, all hardware in your cluster is detected and necessary information are collected for the Ceph configuration.
----
deepsea stage run ceph.stage.1
----

NOTE: Configure cluster and public network in _/srv/pillar/ceph/stack/ceph/cluster.yml_ if not yet done as described in <<create-cluster-yml>>.

Now a _/srv/pillar/ceph/proposals/policy.cfg_ file needs to be created to instruct Deepsea on the location and configuration files to use for the different components that make up the Ceph cluster (Salt master, admin, monitor, OSD and other roles).

To do so, copy the example file to the right location then edit it to match your installation: 
----
cp /usr/share/doc/packages/deepsea/examples/policy.cfg-rolebased /srv/pillar/ceph/proposals/policy.cfg
----

TIP: See <<appendix-policy-cfg>> for the one used when installing the cluster described in this document.

===== Stage 2: Configure
During this stage necessary configuration data are prepared in particular format.
----
deepsea stage run ceph.stage.2
----

[TIP]
====
Use below command to check the attributes of each node:
----
salt '*' pillar.items
----
====

===== Define drive groups
DriveGroups information are defined in the file _/srv/salt/ceph/configuration/files/drive_groups.yml_. It specifies what drives should be used for data device, DB device, or WAL device, and other parameters for setting up the OSDs.

. First take a look of all the disks on all OSD nodes:
+
----
salt-run disks.details
----
+
It lists the vendor, model, size and type of the disks. Those information can be used to match a group of drives and assign them to different uses.

. Now define drive groups in the drive_groups.yml file.
+
TIP: See <<appendix-drive-groups-yml>> for the drive group definition used in this example cluster.
For complete information refers to the https://documentation.suse.com/en-us/ses/6/single-html/ses-deployment/#ds-drive-groups[Deployment Guide]

. After finished editing _drive_groups.yml_, run below commands to see the result definition. Exam it carefully and make sure it meets your expectation before moving on to next step.
+
----
salt-run disks.list
salt-run disks.report
----

===== Stage 3: Deploy
A basic Ceph cluster with mandatory Ceph services is created in this stage.
----
deepsea stage run ceph.stage.3
----

NOTE: It may take quite some time for above command to finish if your cluster is large, your have a lot of disks, or your Internet bandwidth is limited while you didn't register the nodes to local SMT server.

After the above command is finished successfully, check whether the cluster is up by running:
----
ceph -s
----


===== Stage 4: Services
Additional features of Ceph like iSCSI, Object Gateway and CephFS can be installed in this stage. Each is optional and up to your situation. 
----
deepsea stage run ceph.stage.4
----


=== Post-deployment Quick Tests
The steps below can be used (regardless of the deployment method) to validate the overall cluster health:
----
ceph status
ceph osd pool create test 1024
rados bench –p test 300 write --no-cleanup
rados bench –p test 300 seq
----

Once the tests are complete, you can remove the test pool via:
----
ceph tell mon.* injectargs --mon-allow-pool-delete=true
ceph osd pool delete test test --yes-i-really-really-mean-it
ceph tell mon.* injectargs --mon-allow-pool-delete=false
----

endif::[]
ifeval::["{lang}" == "zh_CN"]
endif::[]